{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM Classification from scratch on non linear separable data CASE#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n",
      "2000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#file input\n",
    "\n",
    "x1,y1,x2,y2 = [],[],[],[]\n",
    "\n",
    "with open(r\"data_1\\Class1.txt\") as df :\n",
    "    for line in df:\n",
    "        val = line.split(\",\")\n",
    "        x1.append(float(val[0]))\n",
    "        y1.append(float(val[1]))\n",
    "print(len(x1),len(y1))\n",
    "\n",
    "with open(r\"data_1\\Class2.txt\") as df :\n",
    "    for line in df:\n",
    "        val2 = line.split(\",\")\n",
    "        x2.append(float(val2[0]))\n",
    "        y2.append(float(val2[1]))\n",
    "print(len(x2),len(y2))\n",
    "\n",
    "#dataframe construction\n",
    "\n",
    "Actual_classes =  [1]*len(x1) + [2]*len(x2)\n",
    "X = x1 + x2\n",
    "Y = y1 + y2\n",
    "df = pd.DataFrame()\n",
    "df['X'] = X\n",
    "df['Y'] = Y\n",
    "\n",
    "# to understand the data\n",
    "\n",
    "# plt.scatter(df['X'],df['Y'],c = Actual_classes)\n",
    "# plt.show()\n",
    "def standardisation(dataframe): \n",
    "    return StandardScsaler().fit_transform(dataframe.values)\n",
    "\n",
    "\n",
    "#List of lists of classes 1 and 2 with x and y as inputs\n",
    "def matrix_construct(X,Y):\n",
    "    d1 = [[],[]]\n",
    "    d2 = [[],[]]\n",
    "    for i in range(len(Y)):\n",
    "        Xrow = list(X.iloc[i])\n",
    "        if Y[i] == 1:\n",
    "            d1[0].append(Xrow[0])\n",
    "            d1[1].append(Xrow[1])\n",
    "        elif Y[i] == 2:\n",
    "            Xrow =list(X.iloc[i]) \n",
    "            d2[0].append(Xrow[0])\n",
    "            d2[1].append(Xrow[1])\n",
    "    return d1,d2\n",
    "\n",
    "class GMM:\n",
    "    def __init__(self, n_components, max_iter = 100):\n",
    "        self.q_value = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.pi = [1/self.q_value for _ in range(self.q_value)]\n",
    "        self.class_tag = [index+1 for  index in range(self.q_value)]\n",
    "        \n",
    "    def multivariate_normal(self, X, mean_vector, covariance_matrix):\n",
    "        return ((2*np.pi)**(-len(X)/2))*(np.linalg.det(covariance_matrix)**(-1/2))*np.exp(-(np.dot(np.dot((X-mean_vector).T, np.linalg.inv(covariance_matrix)), (X-mean_vector)))/2)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        SplitData = np.array_split(X, self.q_value)\n",
    "        \n",
    "        # Initial calculation of the mean-vector and covarience matrix\n",
    "        \n",
    "        self.mean_vector = [np.mean(x, axis=0) for x in SplitData]\n",
    "        self.covariance_matrices = [np.cov(x.T) for x in SplitData]\n",
    "        \n",
    "        del SplitData\n",
    "        \n",
    "        for t in range(self.max_iter):\n",
    "            #E- Step\n",
    "            \n",
    "            self.responsibility = np.zeros((len(X), self.q_value))\n",
    "            \n",
    "            for n in range(len(X)):\n",
    "                for k in range(self.q_value):\n",
    "                    num =  self.pi[k] * self.multivariate_normal(X[n], self.mean_vector[k], self.covariance_matrices[k])\n",
    "                    den =  sum([self.pi[j]*self.multivariate_normal(X[n], self.mean_vector[j], self.covariance_matrices[j]) for j in range(self.q_value)])\n",
    "                    self.responsibility[n][k] = num/den\n",
    "           \n",
    "            # Calculating the N\n",
    "            N = np.sum(self.responsibility, axis=0)\n",
    "            \n",
    "            #M-Step\n",
    "            \n",
    "            # initialising the mean vector as a zero vector\n",
    "            self.mean_vector = np.zeros((self.q_value, len(X[0])))\n",
    "            \n",
    "            # Updating the mean vector\n",
    "            for k in range(self.q_value):\n",
    "                for n in range(len(X)):\n",
    "                    self.mean_vector[k] += self.responsibility[n][k] * X[n]\n",
    "            self.mean_vector = [1/N[k]*self.mean_vector[k] for k in range(self.q_value)]\n",
    "            \n",
    "            # intialising the list of the covariance matrices\n",
    "            self.covariance_matrices = [np.zeros((len(X[0]), len(X[0]))) for k in range(self.q_value)]\n",
    "            \n",
    "            # Updating the covariance matrices\n",
    "            for k in range(self.q_value):\n",
    "                self.covariance_matrices[k] = np.cov(X.T, aweights=(self.responsibility[:, k]), ddof=0)\n",
    "                \n",
    "            self.covariance_matrices = [1/N[k]*self.covariance_matrices[k] for k in range(self.q_value)]\n",
    "            \n",
    "            # Updating the pi list\n",
    "            self.pi = [N[k]/len(X) for k in range(self.q_value)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        pdf_values = []\n",
    "        for n in range(len(X)):\n",
    "            pdf_values.append([self.multivariate_normal(X[n], self.mean_vector[k], self.covariance_matrices[k])\n",
    "                           for k in range(self.q_value)])\n",
    "        Cluster = []\n",
    "        for pdf_value in pdf_values:\n",
    "            Cluster.append(self.class_tag[pdf_value.index(max(pdf_value))])\n",
    "        return Cluster\n",
    "\n",
    "def accuracy(val1,val2):\n",
    "    ans = len(val2)\n",
    "    for i in range(len(val1)):\n",
    "        if val1[i] != val2[i]:\n",
    "            ans -= 1\n",
    "    return (ans/len(val2))*100\n",
    "\n",
    "    \n",
    "\n",
    "#main function\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, Actual_classes, test_size=0.3, random_state=42)\n",
    "\n",
    "# mdel = GMM(2)\n",
    "# mdel.fit(X_train.values[:])\n",
    "# scores = mdel.predict(X_test.values[:])B\n",
    "# # print(scores)\n",
    "# # print(Y_test[:])\n",
    "# plt.scatter(X_test['X'][:], X_test['Y'][:], c = Y_test[:])\n",
    "# plt.show()\n",
    "# # print(accuracy(scores,Y_test))\n",
    "# # #the actual test data \n",
    "# plt.scatter(X_test['X'][:], X_test['Y'][:], c = scores)\n",
    "# plt.show()\n",
    "\n",
    "model1 = GMM(2)\n",
    "model1.fit(X_train.values[:])\n",
    "scores = model1.predict(X_train.values[:])\n",
    "# print(scores)\n",
    "# print(Y_test[:])\n",
    "plt.scatter(X_train['X'][:], X_train['Y'][:], c = Y_train[:])\n",
    "plt.show()\n",
    "# #the actual test data \n",
    "plt.scatter(X_train['X'][:], X_train['Y'][:], c = scores)\n",
    "plt.show()\n",
    "\n",
    "# print(\"accuracy percentage\", round(accuracy(scores,Y_test),3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
